% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trendfilter.R
\name{trendfilter}
\alias{trendfilter}
\title{Estimate the trendfilter}
\usage{
trendfilter(
  y,
  x = seq_along(y),
  weights = rep(1, n),
  k = 3L,
  left_boundary_m = NULL,
  right_boundary_m = NULL,
  family = c("gaussian", "logistic", "poisson"),
  method = c("admm", "pdip", "hybrid"),
  lambda = NULL,
  nlambda = 50L,
  lambda_max = NULL,
  lambda_min = NULL,
  lambda_min_ratio = 1e-05,
  standardize = TRUE,
  control = trendfilter_control_list()
)
}
\arguments{
\item{y}{vector of observations of length \code{n}}

\item{x}{vector of positions at which the \code{y} have been observed, defaults
to \code{1:n}. These should be in increasing order, but will be sorted if
necessary.}

\item{weights}{vector of weights for the observations, defaults to \code{rep(1, n)}.
Note that internally, these are rescaled to sum to 1.}

\item{k}{Integer. Degree of the piecewise polynomial curve to be
estimated. For example, \code{k = 0} corresponds to a piecewise constant
curve.}

\item{left_boundary_m}{Integer or 'natural', optional value. Value has to be between
1 to k-1 or 'natural. If Null, use 0. If 'natural', uses value round(k/2). Defaults to \code{NULL}.}

\item{right_boundary_m}{Integer or 'natural', optional value. Value has to be between
1 to k-1 or 'natural. If Null, use 0. If 'natural', uses value round(k/2). Defaults to \code{NULL}.}

\item{family}{Character or function. Specifies the loss function
to use. Valid options are:
\itemize{
\item \code{"gaussian"} - least squares loss (the default),
\item \code{"binomial"} - logistic loss (classification),
\item \code{"poisson"}  - Poisson loss for count data
}

For any other type, a valid \code{\link[stats:family]{stats::family()}} object may be passed. Note
that these will generally be much slower to estimate than the built-in
options passed as strings. So for example, \code{family = "gaussian"} and
\code{family = gaussian()} will produce the same results, but the first
will be much faster.character.}

\item{method}{Character. Specifies the estimation algorithm to use.}

\item{lambda}{Vector. A user supplied sequence of tuning parameters which
determines the balance between data fidelity and smoothness of the
estimated curve; larger \code{lambda} results in a smoother estimate. The
default, \code{NULL} results in an automatic computation based on \code{nlambda},
the largest value of \code{lambda} that would result in a maximally smooth
estimate, and \code{lambda_min_ratio}. Supplying a value of \code{lambda} overrides
this behaviour. It is likely better to supply a
decreasing sequence of \code{lambda} values than a single (small) value. If
supplied, the user-defined \code{lambda} sequence is automatically sorted in
decreasing order.}

\item{nlambda}{Integer. Number of lambda values to use in the sequence.}

\item{lambda_max}{Optional value for the largest \code{lambda} to use.}

\item{lambda_min}{Optional value for the smallest \code{lambda} to use (> 0).}

\item{lambda_min_ratio}{If neither \code{lambda} nor \code{lambda_min} is specified,
\code{lambda_min = lambda_max * lambda_min_ratio}.
A very small value will lead to the solution \code{theta = y} (for the Gaussian
loss). This argument has no effect if there is a user-defined \code{lambda}
sequence.}

\item{standardize}{If \code{TRUE} (the default), \code{y} will be centered and scaled
by its mean and standard deviation (and the operation inverted for \code{theta}
internally). This can significantly speed convergence of the algorithm.}

\item{control}{A list of control parameters for the estimation algorithm.
See the constructor \code{\link[=trendfilter_control_list]{trendfilter_control_list()}}.}
}
\value{
An object with S3 class \code{trendfilter}. Among the list components:
\itemize{
\item \code{y} the input data.
\item \code{x} the vector of positions at which the data have been observed.
\item \code{weights} the vector of observation weights
\item \code{theta} the estimated curve evaluated at \code{x}. This is a matrix with
each column corresponding to one value of \code{lambda}.
\item \code{lambda} the values of \code{lambda} actually used in the algorithm.
\item \code{korder} degree of the estimated piecewise polynomial curve.
\item \code{dof} the estimated degrees of freedom of the solution
\item \code{iters} the required number of iterations for each value of \code{lambda}.
\item \code{objective} the value of the objective function for each value of \code{lambda}.
}
}
\description{
Given observations \eqn{y} at locations \eqn{x} the trendfilter
estimates the regression function \eqn{\theta(x) = E[Y\ |\ X = x]} by
by minimizing the smoothness-penalized negative log-likelihood
of the form:

\deqn{\hat{\theta} = \arg\min_{\theta} \frac{1}{n} \sum_{i=1}^n (y_i -
  \theta_i)^2 + \lambda\Vert \mathbb{D}_n^{(k+1)}\theta\Vert_1, }

where \eqn{\lambda} controls the balance between the fit to the data and the
amount of smoothness, and \eqn{\mathbb{D}_n^{(k+1)}} is the \eqn{(k+1)}-th order
discrete derivative matrix (a function of \eqn{x}).
}
\examples{
x <- 1:100 / 101 * 2 * pi
y <- sin(x) + .2 * rnorm(100)
out <- trendfilter(y, x)

plot(out)
}
\references{
Tibshirani (2014). "Adaptive piecewise polynomial estimation via trend
filtering," \emph{Annals of Statistics}, \strong{42}(1):285–323.
\href{https://www.stat.berkeley.edu/~ryantibs/papers/dspline.pdf}{Link}

Tibshirani (2022), "Divided differences, falling factorials, and
discrete splines: Another look at trend filtering and related problems,"
\emph{Foundations and Trends® in Machine Learning}, \strong{15}(6):694-846.
\href{https://www.stat.berkeley.edu/~ryantibs/papers/trendfilter.pdf}{Link}
}
\seealso{
\code{\link[tvdenoising:tvdenoising]{tvdenoising::tvdenoising()}}
}
